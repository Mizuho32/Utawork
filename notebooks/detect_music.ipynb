{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "\n",
    "vsongrecog_path = os.getcwd()\n",
    "sys.path.append(f\"{vsongrecog_path}/zsass\")\n",
    "sys.path.append(vsongrecog_path)\n",
    "sys.path.append(f\"{vsongrecog_path}/whisper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pathlib\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from py_linq import Enumerable as E\n",
    "\n",
    "import zsass.htsat_config as htsat_config\n",
    "import src.audioclassifier as audioclassifier\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "import src.audioset as aset\n",
    "import src.chart_utils as chart_utils\n",
    "import src.detector as detector\n",
    "import src.transcriber as transcriber\n",
    "import src.Identifier as identifier\n",
    "import notebooks.myconfig as myconfig\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(utils)\n",
    "    importlib.reload(aset)\n",
    "    importlib.reload(chart_utils)\n",
    "\n",
    "    importlib.reload(audioclassifier)\n",
    "    importlib.reload(detector)\n",
    "    importlib.reload(transcriber)\n",
    "    importlib.reload(identifier)\n",
    "    importlib.reload(myconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "onto = utils.Ontology(f'{vsongrecog_path}/ontology/ontology.json')\n",
    "audioset = aset.AudioSet(f\"{vsongrecog_path}/ast/egs/audioset/data/class_labels_indices.csv\")\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "interests = onto[utils.reg(r\"^(Singing|Music)$\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audiocls = audioclassifier.AudioClassifier(htsat_config.resume_checkpoint, htsat_config, interests, onto, audioset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "media_dir = myconfig.media_dir\n",
    "thres_set = detector.Threshold(\n",
    "    thres = 0.60,\n",
    "    human_thres = 0.5,\n",
    "    music_joint_thres = 0.4,\n",
    "    human_joint_thres = 0.3,\n",
    "\n",
    "    adj_thres=5.0, #0.8,\n",
    "    long_thres=50,#10,\n",
    "    hs_rate_thres=0.4,\n",
    "\n",
    "    transc_long_thres=30,\n",
    "    search_len=50,\n",
    ")\n",
    "cut_duration = 10\n",
    "cache_itv = 3\n",
    "print_itv = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "def iter(media_dir, medias = [\"*.flac\", \"*.ogg\"]):\n",
    "    for typ in medias:\n",
    "        for soundfile in sorted(media_dir.glob(typ)):\n",
    "            yield soundfile\n",
    "\n",
    "for wavfile in iter(media_dir)\n",
    "    try:\n",
    "        config = detector.Config(wavfile, cut_duration, thres_set, interests, cache_itv, print_itv)\n",
    "\n",
    "        # Check existance\n",
    "        infer_cache_dir = config.cache_dir / wavfile.stem\n",
    "        cache_exists = infer_cache_dir.exists() and len(list(infer_cache_dir.glob(\"*.pkl\")))\n",
    "\n",
    "        # Instantiate\n",
    "        music_detector = detector.Detector(Audiocls, onto, audioset, config)\n",
    "\n",
    "        if cache_exists:\n",
    "            print(\"Skip Detection\", wavfile.name)\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Detect\", wavfile.name)\n",
    "            music_intervals = music_detector.main(0)\n",
    "            forauda = detector.to_audacity(music_intervals)\n",
    "            utils.save_text(config.input_path.parent / f\"{config.input_path.stem}_mid.txt\", forauda)\n",
    "\n",
    "        # Beautify\n",
    "        all_abst_tensor, all_start, all_duration = detector.Detector.concat_cached_abst(music_detector)\n",
    "        all_itvs = music_detector.abst_tensor2intervals(all_abst_tensor, all_start, all_duration)\n",
    "\n",
    "        utils.save_text(config.input_path.parent / f\"{config.input_path.stem}.txt\", detector.to_audacity(all_itvs))\n",
    "    except FileNotFoundError as ex:\n",
    "        print(wavfile, ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "# https://zenn.dev/layerx/articles/e13030eb8e364a\n",
    "# https://qiita.com/kccs_kai-morita/items/7cc6510b8f483c31bf6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gemini():\n",
    "    genai.configure(api_key=os.environ['API_KEY'])\n",
    "    return genai.GenerativeModel(model_name='gemini-pro')\n",
    "\n",
    "lang_model = gen_gemini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import browser_cookie3\n",
    "reload()\n",
    "\n",
    "\n",
    "engine_type = \"bing\"\n",
    "cj = browser_cookie3.firefox()\n",
    "\n",
    "end_expand = 5.0\n",
    "\n",
    "for wavfile in iter(media_dir)\n",
    "    skipped = False\n",
    "    try:\n",
    "        config = detector.Config(wavfile, cut_duration, thres_set, interests, cache_itv, print_itv)\n",
    "\n",
    "        music_transcriber = transcriber.Transcriber(model, config)\n",
    "        trans_cache_file = config.transcript_cache_dir / wavfile.stem / f\"{wavfile.stem}.pkl\"\n",
    "        output_file = config.output_dir / wavfile.stem / f\"{wavfile.stem}.pkl\"\n",
    "\n",
    "        if trans_cache_file.exists():\n",
    "            transcriptions = music_transcriber.get_cache()\n",
    "            if not len(transcriptions):\n",
    "                print(\"re Transcribe\", wavfile.stem)\n",
    "                transcriptions = music_transcriber.main()\n",
    "            else:\n",
    "                print(\"Skip transcription\", wavfile.name)\n",
    "        else:\n",
    "            print(\"Transcribe\", wavfile.stem)\n",
    "            # do cache also\n",
    "            transcriptions = music_transcriber.main()\n",
    "\n",
    "        music_identifier = identifier.Identifier(engine_type, transcriptions, lang_model, config, cookie_jar=cj)\n",
    "        \n",
    "        if output_file.exists():\n",
    "            identified = music_identifier.get_cache()\n",
    "            if not len(identified):\n",
    "                print(\"re Identify\", wavfile.stem)\n",
    "                identified  = music_identifier.main()\n",
    "            elif len(identified) != len(transcriptions):\n",
    "                print(\"Resume identify\", wavfile.stem)\n",
    "                identified  = music_identifier.main(identified)\n",
    "            else:\n",
    "                print(\"Skip identification\", wavfile.name)\n",
    "                skipped = True\n",
    "        else:\n",
    "            print(\"Identify\", wavfile.stem)\n",
    "            identified  = music_identifier.main()\n",
    "        \n",
    "        print(\"  \", len(identified), \"items\")\n",
    "        music_identifier.save_csv(media_dir, wavfile, identified)\n",
    "\n",
    "        if skipped:\n",
    "            continue\n",
    "    #except grpc.RpcError as e:\n",
    "    except Exception as e:\n",
    "        print(\"ERR\", e)\n",
    "        if \"Too Many\" in str(e):\n",
    "            raise e\n",
    "        lang_model = gen_gemini()\n",
    "\n",
    "    print(\"Sleep...\")\n",
    "    time.sleep(2*60) # For avoid heavy access\n",
    "    print(\"End sleep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "cj = browser_cookie3.firefox()\n",
    "result = identifier.google(\"今日\", cj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "result = identifier.search(\"天気\", \"bing\", cj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "print(not not [])\n",
    "identifier.test()(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "\n",
    "print(len(transcriptions))\n",
    "idx = 3\n",
    "\n",
    "transcription = transcriptions[idx]\n",
    "utils.sec2time(transcription.segment[0]), transcription.lang, transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from dateutil import parser\n",
    "\n",
    "def name_filter(file_path: pathlib.Path):\n",
    "    return True\n",
    "    #return \"7-20\" in file_path.stem\n",
    "\n",
    "def iter():\n",
    "    for typ in [\"*.flac\", \"*.ogg\"]:\n",
    "        for soundfile in media_dir.glob(typ):\n",
    "            yield soundfile\n",
    "\n",
    "end_expand = 5.0\n",
    "\n",
    "for soundfile in iter():\n",
    "    if not name_filter(soundfile):\n",
    "        print(\"Skip\", soundfile.name)\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Write\", soundfile.name)\n",
    "\n",
    "\n",
    "    pkl_file = media_dir / \"identified\" / soundfile.stem / f\"{soundfile.stem}.pkl\"\n",
    "    csv_file = media_dir / \"identified\" / soundfile.stem / f\"{soundfile.stem}.csv\"\n",
    "    csv_data = []\n",
    "\n",
    "    if not pkl_file.exists():\n",
    "        print(pkl_file, \"not found\")\n",
    "        continue\n",
    "\n",
    "    transcriptions: List[transcriber.Transcription] = utils.load_pickle(pkl_file)\n",
    "\n",
    "    #parsed_date = parser.parse(soundfile.name, fuzzy=True)\n",
    "    #dir_name = parsed_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    for idx, transcription in enumerate(transcriptions):\n",
    "        title = transcription.title\n",
    "        #print(title, transcription.search_word)\n",
    "        if not title:\n",
    "            title = \"NoName\" + str(idx)\n",
    "            #continue\n",
    "\n",
    "        command = 'ffmpeg'\n",
    "        start, end = transcription.segment\n",
    "        end += end_expand\n",
    "\n",
    "        csv_data.append([start, end, title, transcription.artist])\n",
    "\n",
    "\n",
    "    with open(csv_file, \"w\", newline=\"\") as file:\n",
    "        mywriter = csv.writer(file, delimiter=\",\")\n",
    "        mywriter.writerows(np.array(csv_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idetify draft codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset for tmp use\n",
    "for idx, tmp in enumerate(transcriptions):\n",
    "    if idx in [4]:#[2, 7]:\n",
    "        tmp.search_result = []\n",
    "        tmp.llm_result = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "transcriptions = [transcriber.Transcription.Renew(t) for t in transcriptions]\n",
    "music_identifier = identifier.Identifier(transcriptions, lang_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = music_identifier.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "\n",
    "transcription = transcriptions[idx]\n",
    "utils.sec2time(transcription.segment[0]), transcription.lang, transcription.text,transcriptions[idx].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "tmp = transcriptions[7]\n",
    "#tmp.search_result = None\n",
    "#tmp.llm_result = \"\"\n",
    "search_word = identifier.Identifier.get_search_word(music_identifier, tmp)\n",
    "print(tmp.search_word,\"\\n\", search_word)\n",
    "\n",
    "tmp.search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = music_identifier.guess_song(tmp)\n",
    "tmp.artist, tmp.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = str.join(\"\\n\", map(lambda line: f\"- {line}\", tmp.search_result))\n",
    "prompt = f\"\"\"\n",
    "Guess the artist and the song name in human understandable Japanese as possible as you can from the list and return it in json format include \"artist\" and \"title\" as keys.\n",
    "If you can't identify them uniquely, the guess from top item of list that include the word \"歌詞\".\n",
    "\n",
    "{list}\n",
    "\"\"\"\n",
    "print(prompt)\n",
    "\n",
    "response = lang_model.generate_content(prompt)\n",
    "#response = music_identifier.model.generate_content(prompt)\n",
    "response.parts[0].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbf651ad57764a85bd0d6253f55158c06e8f62339527fb5be4597f7fba08e70b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
